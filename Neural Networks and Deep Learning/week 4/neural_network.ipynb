{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1674130c-7cf6-48f9-aed6-80a9d9471331",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "825dd383-233d-4f0b-833b-b82c16f061a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) \n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1c8839-8fda-4fb0-ac8c-75bfdd0d12cb",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bf4021c6-0b1c-4a5d-95dc-291213ee31cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid(Z):\n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    cache = Z\n",
    "    return A, cache\n",
    "\n",
    "def relu(Z):\n",
    "    A = np.maximum(0,Z)\n",
    "    assert(A.shape == Z.shape)\n",
    "    cache = Z \n",
    "    return A, cache\n",
    "\n",
    "\n",
    "def relu_backward(dA, cache):\n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True) \n",
    "    dZ[Z <= 0] = 0\n",
    "    assert (dZ.shape == Z.shape)\n",
    "    return dZ\n",
    "\n",
    "def sigmoid_backward(dA, cache):\n",
    "    Z = cache\n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "    assert (dZ.shape == Z.shape)\n",
    "    return dZ\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    train_dataset = h5py.File('W4A2/datasets/train_catvnoncat.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('W4A2/datasets/test_catvnoncat.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5dcb4e-1af3-486a-b4ce-9ac6c3f701da",
   "metadata": {},
   "source": [
    "## Outlining\n",
    "- Initialize the parameters for a two-layer network and for an $L$-layer neural network\n",
    "- Implement the forward propagation module \n",
    "- Compute the loss\n",
    "- Implement the backward propagation module \n",
    "- Finally, update the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9037e01c-3271-48db-b9df-fde147d7862a",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "29fe9684-1060-487f-9aa2-9f76e995ea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layers_dims):\n",
    "    np.random.seed(3)\n",
    "    parameters = {}\n",
    "    L = len(layers_dims)\n",
    "    for i in range(1,L):\n",
    "        parameters['W'+str(i)] = np.random.randn(layers_dims[i],layers_dims[i-1]) * 0.01\n",
    "        parameters['b'+str(i)] = np.zeros((layers_dims[i],1))\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed11d6a8-e250-4f75-953b-bf2ebaee0548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'W1': array([[ 0.01788628,  0.0043651 ,  0.00096497, -0.01863493, -0.00277388],\n",
      "       [-0.00354759, -0.00082741, -0.00627001, -0.00043818, -0.00477218],\n",
      "       [-0.01313865,  0.00884622,  0.00881318,  0.01709573,  0.00050034],\n",
      "       [-0.00404677, -0.0054536 , -0.01546477,  0.00982367, -0.01101068]]), 'b1': array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]]), 'W2': array([[-0.01185047, -0.0020565 ,  0.01486148,  0.00236716],\n",
      "       [-0.01023785, -0.00712993,  0.00625245, -0.00160513],\n",
      "       [-0.00768836, -0.00230031,  0.00745056,  0.01976111]]), 'b2': array([[0.],\n",
      "       [0.],\n",
      "       [0.]])}\n"
     ]
    }
   ],
   "source": [
    "parameters = initialize_parameters_deep([5,4,3])\n",
    "print(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980e1dd5-6e26-4f0d-9865-1e77ea12a169",
   "metadata": {},
   "source": [
    "## Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "613b38a7-8167-423d-8541-7f04c450e686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A,W,B):\n",
    "    Z = np.dot(W,A) + B\n",
    "    cache = (A,W,B)\n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e64e5f0-0331-4666-bdae-62eb5f1e67e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.27865558  1.1166525 ]]\n"
     ]
    }
   ],
   "source": [
    "A = np.random.randn(3,2)\n",
    "B = np.random.randn(1,1)\n",
    "W = np.random.randn(1,3)\n",
    "Z, cache = linear_forward(A,W,B)\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d5d3810-57f6-4568-8a1b-09586c1507c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev,W,b,activation):\n",
    "    if activation == 'sigmoid':\n",
    "        Z, linear_cache = linear_forward(A_prev,W,b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "\n",
    "    elif activation == 'relu':\n",
    "        Z, linear_cache = linear_forward(A_prev,W,b)\n",
    "        A, activation_cache = relu(Z)\n",
    "\n",
    "    cache = (linear_cache, activation_cache)\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43da7b4d-395b-4b37-992b-000c66862242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.82671298 0.88354675]]\n",
      "[[1.56250827 2.02645434]]\n"
     ]
    }
   ],
   "source": [
    "A_prev = np.random.randn(3,2)\n",
    "B = np.random.randn(1,1)\n",
    "W = np.random.randn(1,3)\n",
    "Z, cache = linear_activation_forward(A_prev,W,B,'sigmoid')\n",
    "print(Z)\n",
    "Z, cache = linear_activation_forward(A_prev,W,B,'relu')\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cbc5395a-5962-45ce-8660-ba28e99b027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l_model_forward(X,parameters):\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2\n",
    "    for i in range(1,L):\n",
    "        A_prev = A\n",
    "        A, cache = linear_activation_forward(A_prev,parameters['W'+str(i)],parameters['b'+str(i)],'relu')\n",
    "        caches.append(cache)\n",
    "    AL,cache = linear_activation_forward(A,parameters['W'+str(L)],parameters['b'+str(L)],'sigmoid')\n",
    "    caches.append(cache)\n",
    "    return AL,caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "28f5329e-c6eb-4223-ba51-e106eaf6f3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.30891685 0.42932176 0.28346704 0.26540328]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "X = np.random.randn(5,4)\n",
    "W1 = np.random.randn(4,5)\n",
    "b1 = np.random.randn(4,1)\n",
    "W2 = np.random.randn(3,4)\n",
    "b2 = np.random.randn(3,1)\n",
    "W3 = np.random.randn(1,3)\n",
    "b3 = np.random.randn(1,1)\n",
    "parameters = {\"W1\": W1,\"b1\": b1,\"W2\": W2,\"b2\": b2,\"W3\": W3,\"b3\": b3}\n",
    "AL,caches = l_model_forward(X,parameters)\n",
    "print(AL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e5eb62-1288-41ed-945c-84bf4337fe6c",
   "metadata": {},
   "source": [
    "## Cost Function :\n",
    "$$-\\frac{1}{m} \\sum\\limits_{i = 1}^{m} (y^{(i)}\\log\\left(a^{[L] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[L](i)}\\right))Â $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "08e4d928-7851-47e0-9f7a-c51dac32a51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL,Y):\n",
    "    m = Y.shape[0]\n",
    "    cost = (-1 / m) * (np.dot(Y , np.log(AL).T) + np.dot((1-Y),np.log(1-AL).T))\n",
    "    cost = np.squeeze(cost)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6dea07e8-d2bc-4feb-8277-4c49d53cc887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8393296907380268\n"
     ]
    }
   ],
   "source": [
    "Y = np.asarray([[1, 1, 0]])\n",
    "AL = np.array([[.8,.9,0.4]])\n",
    "cost = compute_cost(AL,Y)\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bee83b-50a9-403c-9be3-352201d2982e",
   "metadata": {},
   "source": [
    "## Backward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e746629e-ad60-456f-a425-60c60f8fab88",
   "metadata": {},
   "source": [
    "$$ dW^{[l]} = \\frac{\\partial \\mathcal{J} }{\\partial W^{[l]}} = \\frac{1}{m} dZ^{[l]} A^{[l-1] T}$$\n",
    "$$ db^{[l]} = \\frac{\\partial \\mathcal{J} }{\\partial b^{[l]}} = \\frac{1}{m} \\sum_{i = 1}^{m} dZ^{[l](i)}$$\n",
    "$$ dA^{[l-1]} = \\frac{\\partial \\mathcal{L} }{\\partial A^{[l-1]}} = W^{[l] T} dZ^{[l]}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d6b3af21-14e5-47e5-9fd5-c3c788ef319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ,cache):\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "    dW = (1/m) * np.dot(dZ,A_prev.T)\n",
    "    db = (1/m) * np.sum(dZ,axis=1,keepdims=True)\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    return dA_prev,dW,db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d5f2de5d-a9d0-47a5-90f8-60072ea5786f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dA_prev: [[-1.15171336  0.06718465 -0.3204696   2.09812712]\n",
      " [ 0.60345879 -3.72508701  5.81700741 -3.84326836]\n",
      " [-0.4319552  -1.30987417  1.72354705  0.05070578]\n",
      " [-0.38981415  0.60811244 -1.25938424  1.47191593]\n",
      " [-2.52214926  2.67882552 -0.67947465  1.48119548]]\n",
      "dW: [[ 0.07313866 -0.0976715  -0.87585828  0.73763362  0.00785716]\n",
      " [ 0.85508818  0.37530413 -0.59912655  0.71278189 -0.58931808]\n",
      " [ 0.97913304 -0.24376494 -0.08839671  0.55151192 -0.10290907]]\n",
      "db: [[-0.14713786]\n",
      " [-0.11313155]\n",
      " [-0.13209101]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "dZ = np.random.randn(3,4)\n",
    "A = np.random.randn(5,4)\n",
    "W = np.random.randn(3,5)\n",
    "b = np.random.randn(3,1)\n",
    "linear_cache = (A, W, b)\n",
    "\n",
    "dA_prev,dW,db = linear_backward(dZ,linear_cache)\n",
    "print(\"dA_prev: \" + str(dA_prev))\n",
    "print(\"dW: \" + str(dW))\n",
    "print(\"db: \" + str(db))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae45edb-b581-4665-868e-793e73acb7ef",
   "metadata": {},
   "source": [
    "$$dZ^{[l]} = dA^{[l]} * g'(Z^{[l]}). $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "80a7b7d6-12f2-47b3-84b6-79679299fdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA,cache,activation):\n",
    "    linear_cache, activation_cache = cache\n",
    "\n",
    "    if activation == 'sigmoid':\n",
    "        dZ = sigmoid_backward(dA,activation_cache)\n",
    "    elif activation == 'relu':\n",
    "        dZ = relu_backward(dA,activation_cache)\n",
    "\n",
    "    dA_prev,dW,db = linear_backward(dZ,linear_cache)\n",
    "    return dA_prev,dW,db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "10cb2d74-a34d-44f5-90e2-e0f3ce5a3faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With sigmoid: dA_prev = \n",
      "[[ 0.11017994  0.01105339]\n",
      " [ 0.09466817  0.00949723]\n",
      " [-0.05743092 -0.00576154]]\n",
      "With sigmoid: dW = \n",
      "[[ 0.10266786  0.09778551 -0.01968084]]\n",
      "With sigmoid: db = \n",
      "[[-0.05729622]]\n",
      "With relu: dA_prev = \n",
      "[[ 0.44090989  0.        ]\n",
      " [ 0.37883606  0.        ]\n",
      " [-0.2298228   0.        ]]\n",
      "With relu: dW = \n",
      "[[ 0.44513824  0.37371418 -0.10478989]]\n",
      "With relu: db = \n",
      "[[-0.20837892]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "dAL = np.random.randn(1,2)\n",
    "A = np.random.randn(3,2)\n",
    "W = np.random.randn(1,3)\n",
    "b = np.random.randn(1,1)\n",
    "Z = np.random.randn(1,2)\n",
    "linear_cache = (A, W, b)\n",
    "activation_cache = Z\n",
    "linear_activation_cache = (linear_cache, activation_cache)\n",
    "dA_prev, dW, db = linear_activation_backward(dAL, linear_activation_cache, activation = \"sigmoid\")\n",
    "print(\"With sigmoid: dA_prev = \\n\" + str(dA_prev))\n",
    "print(\"With sigmoid: dW = \\n\" + str(dW))\n",
    "print(\"With sigmoid: db = \\n\" + str(db))\n",
    "\n",
    "dA_prev, dW, db = linear_activation_backward(dAL, linear_activation_cache, activation = \"relu\")\n",
    "print(\"With relu: dA_prev = \\n\" + str(dA_prev))\n",
    "print(\"With relu: dW = \\n\" + str(dW))\n",
    "print(\"With relu: db = \\n\" + str(db))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1582497b-c917-4e8c-be9e-bdc5ad300254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l_model_backward(AL,Y,caches):\n",
    "    grads = {}\n",
    "    L = len(caches)\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape)\n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, \"sigmoid\")\n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 1)], current_cache, activation = \"relu\")\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "18fab7d8-3ad0-4652-82a0-f24def41662b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dA0 = \n",
      "[[ 0.          0.52257901]\n",
      " [ 0.         -0.3269206 ]\n",
      " [ 0.         -0.32070404]\n",
      " [ 0.         -0.74079187]]\n",
      "dA1 = \n",
      "[[ 0.12913162 -0.44014127]\n",
      " [-0.14175655  0.48317296]\n",
      " [ 0.01663708 -0.05670698]]\n",
      "dW1 = \n",
      "[[0.41010002 0.07807203 0.13798444 0.10502167]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.05283652 0.01005865 0.01777766 0.0135308 ]]\n",
      "dW2 = \n",
      "[[-0.39202432 -0.13325855 -0.04601089]]\n",
      "db1 = \n",
      "[[-0.22007063]\n",
      " [ 0.        ]\n",
      " [-0.02835349]]\n",
      "db2 = \n",
      "[[0.15187861]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.random.seed(3)\n",
    "AL = np.random.randn(1, 2)\n",
    "Y = np.array([[1, 0]])\n",
    "\n",
    "A1 = np.random.randn(4,2)\n",
    "W1 = np.random.randn(3,4)\n",
    "b1 = np.random.randn(3,1)\n",
    "Z1 = np.random.randn(3,2)\n",
    "linear_cache_activation_1 = ((A1, W1, b1), Z1)\n",
    "\n",
    "A2 = np.random.randn(3,2)\n",
    "W2 = np.random.randn(1,3)\n",
    "b2 = np.random.randn(1,1)\n",
    "Z2 = np.random.randn(1,2)\n",
    "linear_cache_activation_2 = ((A2, W2, b2), Z2)\n",
    "\n",
    "caches = (linear_cache_activation_1, linear_cache_activation_2)\n",
    "grads = l_model_backward(AL, Y, caches)\n",
    "\n",
    "print(\"dA0 = \\n\" + str(grads['dA0']))\n",
    "print(\"dA1 = \\n\" + str(grads['dA1']))\n",
    "print(\"dW1 = \\n\" + str(grads['dW1']))\n",
    "print(\"dW2 = \\n\" + str(grads['dW2']))\n",
    "print(\"db1 = \\n\" + str(grads['db1']))\n",
    "print(\"db2 = \\n\" + str(grads['db2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "20769fed-fd8c-4796-9577-895579dccf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(params, grads, learning_rate):\n",
    "\n",
    "    parameters = params\n",
    "    L = len(parameters) // 2 \n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "958af6d7-9a72-4ba9-800b-7e8d7d7e4318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = [[-0.59562069 -0.09991781 -2.14584584  1.82662008]\n",
      " [-1.76569676 -0.80627147  0.51115557 -1.18258802]\n",
      " [-1.0535704  -0.86128581  0.68284052  2.20374577]]\n",
      "b1 = [[-0.04659241]\n",
      " [-1.28888275]\n",
      " [ 0.53405496]]\n",
      "W2 = [[-0.55569196  0.0354055   1.32964895]]\n",
      "b2 = [[-0.84610769]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "W1 = np.random.randn(3,4)\n",
    "b1 = np.random.randn(3,1)\n",
    "W2 = np.random.randn(1,3)\n",
    "b2 = np.random.randn(1,1)\n",
    "parameters = {\"W1\": W1,\"b1\": b1,\"W2\": W2,\"b2\": b2}\n",
    "\n",
    "np.random.seed(3)\n",
    "dW1 = np.random.randn(3,4)\n",
    "db1 = np.random.randn(3,1)\n",
    "dW2 = np.random.randn(1,3)\n",
    "db2 = np.random.randn(1,1)\n",
    "grads = {\"dW1\": dW1,\"db1\": db1,\"dW2\": dW2,\"db2\": db2}\n",
    "parameters = update_parameters(parameters, grads, 0.1)\n",
    "\n",
    "print (\"W1 = \"+ str(parameters[\"W1\"]))\n",
    "print (\"b1 = \"+ str(parameters[\"b1\"]))\n",
    "print (\"W2 = \"+ str(parameters[\"W2\"]))\n",
    "print (\"b2 = \"+ str(parameters[\"b2\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
